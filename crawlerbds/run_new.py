import json
import os
import subprocess
import time

# ===============================
# C·∫•u h√¨nh Crawler (Crawler parameters)
# ===============================
SPIDER_NAME = "bds68_spider"
MIN_PAGE = 1
MAX_PAGE = 1
JUMP_TO_PAGE = 1

# ===============================
# C·∫•u h√¨nh Kafka (Kafka parameters)
# ===============================
# L∆∞u √Ω: H√£y ƒë·∫£m b·∫£o ƒë·ªãa ch·ªâ n√†y ch√≠nh x√°c v·ªõi c·∫•u h√¨nh c·ªßa b·∫°n
KAFKA_BOOTSTRAP_SERVERS = "18.175.97.243:31880"

# ===============================
# Danh s√°ch lo·∫°i b·∫•t ƒë·ªông s·∫£n
# ===============================
# Index s·∫Ω t·ª± ƒë·ªông ch·∫°y t·ª´ 0 t∆∞∆°ng ·ª©ng v·ªõi th·ª© t·ª± trong list
ESTATE_TYPES = [
    "nhamatpho",  # Index 0
    "nharieng",   # Index 1
    "chungcu",    # Index 2
    "bietthu",    # Index 3
    # C√°c lo·∫°i kh√°c (b·ªè comment n·∫øu mu·ªën ch·∫°y)
    # "datbietthu_batch",
    # "datmatpho_batch",
    # ...
]

# File ch·ª©a danh s√°ch t·ªânh th√†nh (ƒë·∫£m b·∫£o file n√†y n·∫±m c√πng th∆∞ m·ª•c)
PROVINCES_FILE = os.path.join("/", "mnt", "e", "hung", "project", "bigdata", "src", "crawlerbds", "provinces.json")
OUTPUT_ROOT_DIR = 'crawled_data'

def main():
    # 1. Ki·ªÉm tra v√† ƒë·ªçc file provinces.json
    if not os.path.exists(PROVINCES_FILE):
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{PROVINCES_FILE}' t·∫°i th∆∞ m·ª•c hi·ªán t·∫°i.")
        return

    try:
        with open(PROVINCES_FILE, 'r', encoding='utf-8') as f:
            provinces = json.load(f)
    except json.JSONDecodeError:
        print(f"‚ùå L·ªói: File '{PROVINCES_FILE}' kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng JSON.")
        return

    total_provinces = len(provinces)

    # 2. V√≤ng l·∫∑p qua t·ª´ng lo·∫°i BƒêS (Outer Loop)
    # enumerate gi√∫p l·∫•y c·∫£ index (0,1,2...) v√† gi√° tr·ªã (nhamatpho, nharieng...)
    for estate_type_idx, kafka_topic in enumerate(ESTATE_TYPES):
        print("=" * 50)
        print(f"‚ñ∂Ô∏è  B·∫Øt ƒë·∫ßu crawl lo·∫°i BƒêS: {kafka_topic} (estate_type = {estate_type_idx})")
        print("=" * 50)

        # 3. V√≤ng l·∫∑p qua t·ª´ng t·ªânh (Inner Loop)
        for count, province in enumerate(provinces, 1):
            slug = province.get('slug')
            name = province.get('name')

            if not slug:
                print(f"‚ö†Ô∏è C·∫£nh b√°o: D·ªØ li·ªáu t·ªânh thi·∫øu slug, b·ªè qua. (Data: {province})")
                continue

            print(f"[{count}/{total_provinces}] ƒêang crawl: {name} ({slug})")

            # T·∫°o th∆∞ m·ª•c output: crawled_data/{slug}
            output_dir = os.path.join(OUTPUT_ROOT_DIR, slug)
            os.makedirs(output_dir, exist_ok=True)

            # ƒê∆∞·ªùng d·∫´n file output JSON
            output_filename = f"{SPIDER_NAME}_{slug}_{kafka_topic}.json"
            output_path = os.path.join(output_dir, output_filename)

            # X√¢y d·ª±ng c√¢u l·ªánh Scrapy
            # T∆∞∆°ng ƒë∆∞∆°ng v·ªõi: scrapy crawl ... -a ... -s ...
            cmd = [
                "scrapy", "crawl", SPIDER_NAME,
                "-a", f"min_page={MIN_PAGE}",
                "-a", f"max_page={MAX_PAGE}",
                "-a", f"province={slug}",
                "-a", f"jump_to_page={JUMP_TO_PAGE}",
                "-a", f"estate_type={estate_type_idx}",
                "-O", output_path,          # -O vi·∫øt hoa ƒë·ªÉ ghi ƒë√® (overwrite), d√πng -o ƒë·ªÉ n·ªëi (append)
                "-s", "DOWNLOAD_DELAY=5",
                "-s", f"KAFKA_BOOTSTRAP_SERVERS={KAFKA_BOOTSTRAP_SERVERS}",
                "-s", f"KAFKA_TOPIC={kafka_topic}"
            ]

            # Th·ª±c thi l·ªánh
            try:
                # subprocess.run ch·ªù l·ªánh ch·∫°y xong m·ªõi ƒëi ti·∫øp
                subprocess.run(cmd, check=True) 
                print(f"‚úÖ Ho√†n th√†nh: {name}\n")
            except subprocess.CalledProcessError as e:
                print(f"‚ùå L·ªói khi ch·∫°y Scrapy cho {name}: {e}\n")
            except FileNotFoundError:
                print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y l·ªánh 'scrapy'. H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ k√≠ch ho·∫°t m√¥i tr∆∞·ªùng ·∫£o (virtualenv).\n")
                return

            # Sleep 2 gi√¢y gi·ªØa c√°c l·∫ßn crawl t·ªânh
            time.sleep(2)

        print(f"üéØ Ho√†n t·∫•t crawl cho lo·∫°i BƒêS: {kafka_topic}\n")

    print("üèÅ To√†n b·ªô qu√° tr√¨nh crawl ƒë√£ ho√†n t·∫•t!")

if __name__ == "__main__":
    main()