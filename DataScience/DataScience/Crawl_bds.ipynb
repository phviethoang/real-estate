{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZXy25VUm2b6"
      },
      "source": [
        "# **DATA CRAWLING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uOFIsmYm5ug"
      },
      "source": [
        "## **SET UP ENVIRONMENT**\n",
        "\n",
        "**|!!!| NOTE: *Run in GG Colab if not custom path***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vko3tIUmxLd",
        "outputId": "3d844219-c201-49cf-80d3-9199e70a0f12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'real-estate'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 41 (delta 9), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (41/41), 55.97 KiB | 2.07 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!rm -rf /content/real-estate/\n",
        "!git clone -b An https://github.com/phviethoang/real-estate.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEzXn5kxnV7_",
        "outputId": "bcbabb27-742e-47de-f8a1-cb30ce18939f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/real-estate/DataScience/DataScience/DataScience\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.13.5)\n",
            "Requirement already satisfied: cloudscraper in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.2.71)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: playwright in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (1.55.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (5.4.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r requirements.txt (line 1)) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.4.7 in /usr/local/lib/python3.12/dist-packages (from cloudscraper->-r requirements.txt (line 2)) (3.2.5)\n",
            "Requirement already satisfied: requests>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from cloudscraper->-r requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: requests-toolbelt>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from cloudscraper->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: pyee<14,>=13 in /usr/local/lib/python3.12/dist-packages (from playwright->-r requirements.txt (line 5)) (13.0.0)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.12/dist-packages (from playwright->-r requirements.txt (line 5)) (3.2.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.9.2->cloudscraper->-r requirements.txt (line 2)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.9.2->cloudscraper->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.9.2->cloudscraper->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.9.2->cloudscraper->-r requirements.txt (line 2)) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "%cd /content/real-estate/DataScience/DataScience/DataScience\n",
        "!pip install -r requirements.txt\n",
        "!playwright install chromium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEkgnz6BoEar"
      },
      "source": [
        "## **CRAWL DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4X98WY-n3qL",
        "outputId": "c9ce1020-52ff-4989-86c6-fea5152f396b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/real-estate/DataScience/DataScience/DataScience\n",
            "------ GETTING LISTS OF URLS -----\n",
            "/ Showing html file /content/real-estate/DataScience/DataScience/DataScience/tem.html ...\n",
            "Successfully getting 30 urls\n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n",
            "       Finish crawling!                                     \n"
          ]
        }
      ],
      "source": [
        "%cd /content/real-estate/DataScience/DataScience/DataScience/\n",
        "!python DataCrawling.py --links_list_html /content/real-estate/DataScience/DataScience/DataScience/tem.html \\\n",
        "                        --links_list_url https://batdongsan.com.vn/tin-tuc \\\n",
        "                        --save_path /content/real-estate/data.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY6anTMDoqWz",
        "outputId": "79aa9688-453d-429a-a6ac-472c8b4909ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/real-estate\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "%cd /content/real-estate/\n",
        "data_path = \"data.json\"\n",
        "\n",
        "with open(data_path, \"r\", encoding = \"utf-8\") as f:\n",
        "  articles_ls = json.load(f)\n",
        "\n",
        "title_ls = []\n",
        "url_ls = []\n",
        "\n",
        "for article in articles_ls:\n",
        "  title_ls.append(article[\"title\"])\n",
        "  url_ls.append(article[\"url\"])\n",
        "\n",
        "df_data = pd.DataFrame(\n",
        "    {\n",
        "        \"title\": title_ls,\n",
        "        \"url\": url_ls\n",
        "    }\n",
        ")\n",
        "\n",
        "excel_file = \"data.xlsx\"\n",
        "df_data.to_excel(excel_file, index = False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8WXadBU1gWF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
